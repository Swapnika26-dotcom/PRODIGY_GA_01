# PRODIGY_GA_01
Task-01: Text Generation with GPT-2
Objective
The objective of this task is to generate coherent and contextually relevant text using a pre-trained GPT-2 model. The model is fine-tuned on a custom text dataset and used to produce new text based on a user-defined prompt.

Platform
Google Colab / Jupyter Notebook

Model Used
GPT-2 (pre-trained language model)
Technologies Used
Python
Hugging Face Transformers
PyTorch
Datasets library
Dataset
A small custom text dataset was created and used for fine-tuning the GPT-2 model. The dataset consists of simple text sentences related to artificial intelligence and machine learning.

Methodology
Installed required libraries in Google Colab.
Loaded the pre-trained GPT-2 model and tokenizer.
Prepared and tokenized a custom text dataset.
Fine-tuned the GPT-2 model on the dataset.
Generated new text using a user-provided prompt.
Sample Prompt
# PRODIGY_GA_02
Task-02: Image Generation using Pre-trained Model
Objective
Generate images from text prompts using a pre-trained Stable Diffusion model.

Platform
Google Colab / Jupyter Notebook

Model Used
Stable Diffusion v1.5

Technologies
Python
Diffusers
PyTorch
Transformers
Sample Prompt
A futuristic city at sunset, digital art

Output
An AI-generated image based on the given text prompt.
# PRODIGY_GA_03
Task-03: Markov Chain Text Generator
Description

This task implements a Markov Chainâ€“based text generator using Google Colab.
The program accepts user input text and generates new text based on probabilistic word transitions.

Technologies Used

Python

Google Colab

Features

User input through interactive text box

Button-based text generation

Markov chain logic

Example

Input:

machine learning generates text


Output:

learning generates text

Conclusion

Task-03 demonstrates a simple and effective use of Markov Chains for text generation, suitable for academic assignments.
# PRODIGY_GA_04
Project Title
Image to Image Translation using GANs

Description
This project focuses on Image to Image Translation using Generative Adversarial Networks. The model learns to convert an input image into a corresponding target image by training on paired datasets. It demonstrates how deep learning can be used for tasks such as image enhancement, style transfer, and domain conversion.

Developed as part of my internship at Prodigy InfoTech, this project provided hands on experience with deep learning workflows, GAN architecture design, and TensorFlow implementation.

Features
Image to Image Translation using GAN
Generator and Discriminator model implementation
Training using paired image datasets
Loss visualization during training
Sample output image generation after each epoch

Technologies Used
Python
TensorFlow
Keras
NumPy
Matplotlib
Google Colab

Project Workflow
Data Collection and Preprocessing
Building Generator Network
Building Discriminator Network
Defining GAN Loss Functions
Training the GAN Model
Generating and Visualizing Output Images

Results
The trained model successfully learns the mapping between input and target images. Over multiple epochs, the generator improves its ability to create realistic translated images while the discriminator becomes better at distinguishing real and generated outputs.

Learning Outcomes
Understanding GAN architecture
Experience with TensorFlow model training
Working with image datasets
Debugging deep learning training errors
Visualizing model performance

Internship Acknowledgement
This project was developed during my internship at Prodigy InfoTech. I would like to thank the organization for providing the opportunity to work on real world deep learning applications and enhance my practical knowledge.

How to Run
Upload the dataset to Google Colab
Install required libraries
Run training cells step by step
Monitor generator and discriminator loss
Generate sample translated images

Future Enhancements
Training on larger datasets
Improving image resolution
Hyperparameter tuning
Deploying the model as a web application
